{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1tI40MvHf4hu"
   },
   "source": [
    "# <a name=\"gotop\"></a>Table of Contents\n",
    "[Points to Remember](#points)\n",
    "\n",
    "[Numpy](#startingnumpy)\n",
    "   + [Advantages of Numpy](#numpyadvantages)\n",
    "   + [Creating Array](#array)\n",
    "   + [Coverting list to array using numpy](#listtoarray)\n",
    "   + [Array Indexing](#arrayindexing)\n",
    "   + [Array Slicing](#arrayslicing)\n",
    "   + [Array Concatenation](#arrayconcatenation)\n",
    "\n",
    "[Pandas](#pandas)\n",
    "\n",
    "[Exploring ML Dataset](#exploring)\n",
    "\n",
    "[Building a ML Model using Random Forest](#building)\n",
    "+ [Building the model](#buildingthemodel)\n",
    "+ [Predicting the accuracy](#prediction)\n",
    "#Introduction to Numpy and Pandas\n",
    "\n",
    "The pandas library has emerged into a power house of data manipulation tasks in python since it was developed in 2008. With its intuitive syntax and flexible data structure, it's easy to learn and enables faster data computation. The development of numpy and pandas libraries has extended python's multi-purpose nature to solve machine learning problems as well. The acceptance of python language in machine learning has been phenomenal since then.\n",
    "\n",
    "In this tutorial, we'll learn about using numpy and pandas **libraries for data manipulation** from scratch. Instead of going into theory, we'll take a practical approach. First, we'll understand the syntax and commonly used functions of the respective libraries. Later, we'll work on a real-life data set.\n",
    "\n",
    "**Note**: This tutorial is best suited for people who know the basics of python. No further knowledge is expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZs57EijgmoW"
   },
   "source": [
    "##<a name=\"points\"></a>Points to be Remembered\n",
    "\n",
    "+ The data manipulation capabilities of pandas are built on top of the numpy library. In a way, numpy is a dependency of the pandas library.\n",
    "\n",
    "+ Pandas is best at handling tabular data sets comprising different variable types (integer, float, double, etc.). In addition, the pandas library can also be used to perform even the most naive of tasks such as loading data or doing feature engineering on time series data.\n",
    "\n",
    "+ Numpy is most suitable for performing basic numerical computations such as mean, median, range, etc. Alongside, it also supports the creation of multi-dimensional arrays.\n",
    "\n",
    "+ Numpy library can also be used to integrate C/C++ and Fortran code.\n",
    "\n",
    "+ Remember, python is a zero indexing language unlike R where indexing starts at one.\n",
    "\n",
    "+ The best part of learning pandas and numpy is the strong active community support you'll get from around the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUz4xuJ9VbzL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ib95u7TDg7Ra"
   },
   "source": [
    "## Environment to be used\n",
    "At present, we can use [Google Colaboratory](https://colab.research.google.com) for trying out what we are learning. Guess what's the advantage,\n",
    "+ No installation needed\n",
    "+ Easily accessible online\n",
    "+ Pre-installed packages\n",
    "\n",
    "**Note:** If you are about to use a data set that you would like to upload to colab, errors might occur on chrome, try using Firefox if any error occurs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awn2MG1Wiipu"
   },
   "source": [
    "# <a name=\"startingnumpy\"></a>Starting off with Numpy\n",
    "\n",
    "\n",
    "**Numpy** is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays. The ancestor of NumPy was Numeric. In 2005, Travis Oliphant created NumPy by incorporating features of the competing Numarray into Numeric, with extensive modifications. NumPy is open-source software and has many contributors. \n",
    "\n",
    "**<a name=\"numpyadvantages\"></a>Advantages of Numpy**\n",
    "\n",
    "It contains among other things:\n",
    "\n",
    "+ a powerful N-dimensional array object\n",
    "+ sophisticated (broadcasting) functions\n",
    "+ tools for integrating C/C++ and Fortran code\n",
    "+ useful linear algebra, Fourier transform, and random number capabilities\n",
    "+ Size - Numpy data structures take up less space\n",
    "+ Performance - they have a need for speed and are faster than lists\n",
    "+ Functionality - SciPy and NumPy have optimized functions such as linear algebra operations built in.\n",
    "\n",
    "Besides its obvious scientific uses, NumPy can also be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined. This allows NumPy to seamlessly and speedily integrate with a wide variety of databases.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qq_KmxS_if93",
    "outputId": "1d6b88af-f70d-4de0-acd8-a67c1dde531c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After opening a new project on Google colab, let's first import Numpy. \n",
    "\n",
    "#load the library and check its version, just to make sure we aren't using an older version\n",
    "import numpy as np\n",
    "np.__version__\n",
    "#the output of the above command shows the version version of numpy available on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dw7xgdYWjehp"
   },
   "source": [
    "Next, we can create a list of numbers ranging from 0 to 50, to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "AelE2h9mjbCA",
    "outputId": "fbb8e947-3c0e-47cc-c02c-34f8f0adb2fd"
   },
   "outputs": [],
   "source": [
    "# we are using the list and range function to create the list of numbers\n",
    "# Create a list of numbers from 0 to 50.\n",
    "\n",
    "#The above two lines create and prints a list of numbers ranging from 0 to 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EkkhQEkj-Dg"
   },
   "source": [
    "Next, we can convert the integers to string. Converting integers to string / this style of handling lists is known as **list comprehension.**\n",
    "List comprehension offers a versatile way to handle list manipulations tasks easily. We'll learn about them in other examples. Here's an example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtY5iv2lj20E"
   },
   "outputs": [],
   "source": [
    "# Use list comprehension to create a list by converting the list values to string.\n",
    "str_nums = \n",
    "# Use list comprehension to create a list with the elements of the type of the list.\n",
    "type_list = \n",
    "print(\"String List: \", str_nums[:5], \"Type List: \", type_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DxW-q9pk-YT"
   },
   "source": [
    "### <a name=\"array\"></a>Creating Arrays\n",
    "Numpy arrays are homogeneous in nature, i.e., they comprise one data type (integer, float, double, etc.) unlike lists.\n",
    "The following examples shows how to create:\n",
    "+ array with predefined values\n",
    "+ array with a set sequence\n",
    "+ array of even space between the given range of values\n",
    "+ identity matrix\n",
    "\n",
    "It's pretty much simple. Take a look at the example below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "c03r1RbLlDqT",
    "outputId": "bcddd7f7-0050-4da6-fbec-a9cd875504ac"
   },
   "outputs": [],
   "source": [
    "# We can create an array of zeroes using numpy directly.\n",
    "zeros_array = \n",
    "print(\"Array with all zeros: \\n\\n\", zeros_array, \"\\n\")\n",
    "\n",
    "\n",
    "# Here we are creating a 3 row x 5 column matrix\n",
    "ones_array = \n",
    "print(\"Array with all ones: \\n\\n\", ones_array, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wdjSkhjRmYUg",
    "outputId": "46bf6631-808b-4276-a60e-63ef1b5f4e50"
   },
   "outputs": [],
   "source": [
    "# creating a matrix with a predefined value\n",
    "using_full = \n",
    "print(using_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "svoU_3PDmZ_B",
    "outputId": "500cab4f-31e2-4014-c22b-5da0fe2f3261"
   },
   "outputs": [],
   "source": [
    "\n",
    "#create an array with a set sequence\n",
    "using_arrange = \n",
    "print(using_arrange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kE9tvOnqmd9_",
    "outputId": "dc728c80-a958-49da-b671-41cda07bc6c6"
   },
   "outputs": [],
   "source": [
    "#create an array of even space between the given range of values\n",
    "using_linspace = \n",
    "print(using_linspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Bd8Nt65vmgiq",
    "outputId": "525dc143-0f0a-4d17-9f44-bbbb0873e606"
   },
   "outputs": [],
   "source": [
    "#create a 3x3 array with mean 0 and standard deviation 1 in a given dimension\n",
    "a = \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "GP5GRUFpmkMg",
    "outputId": "5040f83e-9dc6-4e8d-a46d-f0812949c512"
   },
   "outputs": [],
   "source": [
    "#create an identity matrix\n",
    "id_matrix = \n",
    "print(id_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "HEvZmRptmn-T",
    "outputId": "6c9c0d09-5994-46fc-9c2a-07bafa546c40"
   },
   "outputs": [],
   "source": [
    "#setting a random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "x1 =  #one dimension\n",
    "x2 =  #two dimension\n",
    "x3 =  #three dimension\n",
    "\n",
    "print(x1, x2, x3)\n",
    "\n",
    "# Printing the various attributes\n",
    "print(\"x3 ndim:\", x3.ndim)\n",
    "print(\"x3 shape:\", x3.shape)\n",
    "print(\"x3 size: \", x3.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReKauGyxcuLP"
   },
   "source": [
    "### <a name=\"listtoarray\"></a>Converting lists to array using Numpy\n",
    "\n",
    "One of the main advantage of Numpy is the fact that, lists can be easily coverted to arrays using numpy. \n",
    "\n",
    "In the below code, we can convert the numbers list created to an array using Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "PZ8CxQowc3mO",
    "outputId": "8ea85a89-7c0e-4d5d-a89a-d1014b7be463"
   },
   "outputs": [],
   "source": [
    "numbers = [10, 20, 30, 40, 50, 60]\n",
    "numbers_array = # Create the array from list.\n",
    "numbers_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHxGc9pkW_1C"
   },
   "source": [
    "Next, we can move on to Array Indexing\n",
    "\n",
    "## <a name=\"arrayindexing\"></a>Array Indexing\n",
    "\n",
    "The important thing to remember is that indexing in python starts at zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZLjdLNWyYQ3c",
    "outputId": "77b73736-9760-47a0-8358-51a4b7795a90"
   },
   "outputs": [],
   "source": [
    "x1 = np.array([4, 3, 4, 4, 8, 4])\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oxhMb1BdYuDh",
    "outputId": "1ef8cbb9-917e-4c99-fa3f-3d1d50c4b9a5"
   },
   "outputs": [],
   "source": [
    "#assess value to index zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vHmojrJtYukJ",
    "outputId": "fa00d486-2c6f-473e-a855-c5c523b3c15d"
   },
   "outputs": [],
   "source": [
    "#assess fifth value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KpUNwSw0YxGj",
    "outputId": "4d0cd78f-9d93-4d89-b2c7-b23dd4cac922"
   },
   "outputs": [],
   "source": [
    "#get the last value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qrcgpUFfYzSb",
    "outputId": "f5807f64-2d70-4994-b333-d7c7d33667c6"
   },
   "outputs": [],
   "source": [
    "#get the second last value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62_qR8BjY01C"
   },
   "outputs": [],
   "source": [
    "##in a multidimensional array, we need to specify row and column index\n",
    "x2 = np.array([[3, 7, 5, 5],\n",
    "      [0, 1, 5, 9],\n",
    "      [3, 0, 5, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QiHerKhmY4b0",
    "outputId": "ba13d8d8-7caa-426e-ec57-e67ec4488ef4"
   },
   "outputs": [],
   "source": [
    "##1st row and 2nd column value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3o6AEqvZCIv"
   },
   "outputs": [],
   "source": [
    "#3rd row and last value from the 3rd column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cprLaXShZD7Z"
   },
   "outputs": [],
   "source": [
    "#replace value at 0,0 index\n",
    "\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olTKJFXQZZ13"
   },
   "source": [
    "## <a name=\"arrayslicing\"></a>Array Slicing\n",
    "Now, we'll learn to access multiple or a range of elements from an array. Contents of ndarray object can be accessed and modified by indexing or slicing, just like Python's in-built container objects.\n",
    "\n",
    "As mentioned earlier, items in ndarray object follows zero-based index. Three types of indexing methods are available − field access, basic slicing and advanced indexing.\n",
    "\n",
    "Basic slicing is an extension of Python's basic concept of slicing to n dimensions. A Python slice object is constructed by giving start, stop, and step parameters to the built-in slice function. This slice object is passed to the array to extract a part of array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2m77w2hcZUdu",
    "outputId": "d54f1241-5cab-4411-b352-5ef431dd5f1b"
   },
   "outputs": [],
   "source": [
    "#first lets create an array in the range of 10\n",
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4g1an9bLZo89",
    "outputId": "85aef538-6dc1-48eb-a890-d94aaa92b1dd"
   },
   "outputs": [],
   "source": [
    "#from start to 4th position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DK7aQdE9Zt05",
    "outputId": "77ec693f-cb40-4d89-9faa-efcb39e5249f"
   },
   "outputs": [],
   "source": [
    "#from 4th position to end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AwXM3WKOZ1DH",
    "outputId": "4ef37174-a2ad-4174-987d-5673e665cca3"
   },
   "outputs": [],
   "source": [
    "#from 4th to 6th position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ME6rqBx2Z4Oe",
    "outputId": "bec33d24-c58b-4917-d469-1d84b70f2a3a"
   },
   "outputs": [],
   "source": [
    "#return elements at even place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MmoIJmLfZ5xc",
    "outputId": "1b76e4b3-297a-4f58-d3f9-12bc50d31fd2"
   },
   "outputs": [],
   "source": [
    "#return elements from first position step by two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TJHJ4rdaZ7wR",
    "outputId": "cba5f203-0190-43dc-cc2d-f292c2164183"
   },
   "outputs": [],
   "source": [
    "#reverse the array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKd_3OpHZ-9G"
   },
   "source": [
    "## <a name=\"arrayconcatenation\"></a>Array Concatenation\n",
    "Many a time, we are required to combine different arrays. So, instead of typing each of their elements manually, you can use array concatenation to handle such tasks easily, OR \n",
    "Often you may have two or more NumPY arrays and want to concatenate/join/merge them into a single array. Python offers multiple options to join/concatenate NumPy arrays.\n",
    "\n",
    "Common operations include given two 2d-arrays, how can we concatenate them row wise or column wise. NumPy’s concatenate function allows you to concatenate two arrays either by rows or by columns. Let us see a couple of examples of NumPy’s concatenate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CFG-7nXWZ-Dj",
    "outputId": "3495d403-12d5-45a7-fb5c-005b32fb98ee"
   },
   "outputs": [],
   "source": [
    "#let's start by creating 2 simple arrays\n",
    "#You can concatenate two or more arrays at once.\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([3, 2, 1])\n",
    "z = [21,21,21]\n",
    "concatenated_arr = # Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wyH5FE-raZXR",
    "outputId": "7bba0ab9-a1d7-4338-ebb8-1244634a3eaf"
   },
   "outputs": [],
   "source": [
    "#You can also use this function to create 2-dimensional arrays.\n",
    "grid = np.array([[1,2,3],[4,5,6]])\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3z2jQ19HabDq"
   },
   "outputs": [],
   "source": [
    "#Use its axis parameter to define row-wise or column-wise matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMwFwmM8armj"
   },
   "source": [
    "#### Also, we can split the arrays based on pre-defined positions. Let's see how!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L58JQU2Famum",
    "outputId": "55455b29-f58d-4572-c86e-71c1a47e4062"
   },
   "outputs": [],
   "source": [
    "#creating an array in the range of 10\n",
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0Cl_bIv0ax92",
    "outputId": "dab22aae-a01d-4d80-85f4-2b5fc7e9ca31"
   },
   "outputs": [],
   "source": [
    "#Now, let's split this array at 3rd and 6th positions\n",
    "\n",
    "print(x1,x2,x3)\n",
    "#the output will have 3 arrays, having 3 elements in the first two and 4 elements in the third array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFJjX-I5bcUF"
   },
   "source": [
    "## <a name=\"arrayconcatenation\"></a> Mathematical Fucntions\n",
    "In addition to the functions we learned above, there are several other mathematical functions available in the numpy library such as sum, divide, multiple, abs, power, mod, sin, cos, tan, log, var, min, mean, max, etc. which you can be used to perform basic arithmetic calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding the sum of two arrays.\n",
    "Numpy arrays can be used for finding the sum of the numbers of two arrays in the same position. I.e instead of looping over the length of two arrays and finding the sum, we can add them up as regular numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the two numpy arrays together.\n",
    "x+x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Power of Vectorization\n",
    "Vectorization is a very powerful concept where the summation of an array can be done parallelly, thereby increasing speed. Let us now compare how this will give us speed improvements compared to a normal list by comparing the time taken to double the elements of a list vs the time taken to double the values of the numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken =  0.02624225616455078\n"
     ]
    }
   ],
   "source": [
    "# Create an list with elements from 0 to 100000\n",
    "a = [i for i in range(0, 100000)]\n",
    "# Clock the start time\n",
    "start_time = time.time()\n",
    "# Start the loop for the operation\n",
    "for i in range(0, 100000):\n",
    "    a[i] = a[i]*2\n",
    "print(\"Total time taken = \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the same for a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken =  0.0004336833953857422\n"
     ]
    }
   ],
   "source": [
    "# Create a numpy array with elements from 0 to 100000\n",
    "a = np.arange(0, 100000)\n",
    "# Clock the start time\n",
    "start_time = time.time()\n",
    "# Start the loop for the operation\n",
    "a = a*2\n",
    "print(\"Total time taken = \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the improvements in speed is immense. This helps us a lot when we are processing data of a large length.\n",
    "\n",
    "Apart from the summation and multiplication, we can perform all the standard arthmetic operations in this manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other operations on a numpy array\n",
    "A numpy array has built in functions for computing mean, median, sum, etc. They can be done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New numpy array\n",
    "np_arr = np.arange(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the various attributes of the array.\n",
    "mean = \n",
    "std = \n",
    "arr_sum = \n",
    "print(mean, std, arr_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nznD-3cpb42a"
   },
   "source": [
    "Let's move on to pandas now. Make sure you following each line below because it'll help you in doing data manipulation using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDV7By_Zb-gX"
   },
   "source": [
    "# <a name=\"pandas\"></a>Pandas\n",
    "\n",
    "Pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. It is free software released under the three-clause BSD license. The name is derived from the term \"panel data\", an econometrics term for data sets that include observations over multiple time periods for the same individuals.\n",
    "\n",
    "**Library features**\n",
    "\n",
    "+ DataFrame object for data manipulation with integrated indexing.\n",
    "\n",
    "+ Tools for reading and writing data between in-memory data structures and different file formats.\n",
    "\n",
    "+ Data alignment and integrated handling of missing data.\n",
    "\n",
    "+ Reshaping and pivoting of data sets.\n",
    "\n",
    "+ Label-based slicing, fancy indexing, and subsetting of large data sets.\n",
    "\n",
    "+ Data structure column insertion and deletion.\n",
    "\n",
    "+ Group by engine allowing split-apply-combine operations on data sets.\n",
    "\n",
    "+ Data set merging and joining.\n",
    "\n",
    "+ Hierarchical axis indexing to work with high-dimensional data in a lower-dimensional data \n",
    "structure.\n",
    " \n",
    "+ Time series-functionality: Date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging.\n",
    "\n",
    "+ Provides data filtration.\n",
    "\n",
    "The library is highly optimized for performance, with critical code paths written in Cython or C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-LCML6VcyZ6"
   },
   "outputs": [],
   "source": [
    "# First, we can import Pandas\n",
    "import pandas as pd\n",
    "\n",
    "#here, pd is just an alias for the name pandas (short hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fkFAEQ2Vc7AI",
    "outputId": "dc11ee45-0a7a-432a-98f8-d0fc660187c3"
   },
   "outputs": [],
   "source": [
    "# Now we can create a data frame - dictionary is used here where keys get converted to column names and values to row values.\n",
    "data = pd.DataFrame({'Country': ['Russia','Colombia','Chile','Equador','Nigeria'],\n",
    "                    'Rank':[121,40,100,130,11]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "-S_QqW4_c_Zr",
    "outputId": "67ccae79-be54-46a5-8fc1-74cb07c7b3f9"
   },
   "outputs": [],
   "source": [
    "#We can do a quick analysis of any data set using describe():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hmj8NkNFdGbh"
   },
   "source": [
    "Remember, describe() method computes summary statistics of integer / double variables. To get the complete information about the data set, we can use info() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "dtEcIqcJdEVe",
    "outputId": "70b9cb97-e940-4c99-a639-e9ea4bc29e9e"
   },
   "outputs": [],
   "source": [
    "#Among other things, it shows the data set has 5 rows and 2 columns with their respective names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRTfjvORdN-8"
   },
   "outputs": [],
   "source": [
    "#Let's create another data frame.\n",
    "data = pd.DataFrame({'group':['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],'ounces':[4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0RJgFdzdTG8"
   },
   "outputs": [],
   "source": [
    "#Let's sort the data frame by ounces - inplace = True will make changes to the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltKjfmhBdW-d"
   },
   "source": [
    "### <a name=\"sortingpandas\"></a>Sorting the data\n",
    "We can sort the data by not just one column but multiple columns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEAm3PSMdVMK"
   },
   "outputs": [],
   "source": [
    "# Sort the data using the column names group and ounces in ascending and descending respectively:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mc7APRN8daqF"
   },
   "source": [
    "Often, we get data sets with duplicate rows, which is nothing but noise. Therefore, before training the model, we need to make sure we get rid of such inconsistencies in the data set. Let's see how we can remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJB194f9dYg0"
   },
   "outputs": [],
   "source": [
    "#create another data with duplicated rows\n",
    "data = \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJCbqFoWdcql"
   },
   "outputs": [],
   "source": [
    "#sort values with k2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJeG4ov5deRi"
   },
   "outputs": [],
   "source": [
    "#remove duplicates - ta da! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFgRXc2bdhcE"
   },
   "source": [
    "Here, we removed duplicates based on matching row values across all columns. Alternatively, we can also remove duplicates based on a particular column. Let's remove duplicate values from the k1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnAd8Gixdfvu"
   },
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1xpGOeKdlMl"
   },
   "source": [
    "Now, we will learn to categorize rows based on a predefined criteria. It happens a lot while data processing where you need to categorize a variable. For example, say we have got a column with country names and we want to create a new variable 'continent' based on these country names. In such situations, we will require the steps below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LtF5RcXdnH-"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami','corned beef', 'Bacon', 'pastrami', 'honey ham','nova lox'],\n",
    "                 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-D7iIpSdrRn"
   },
   "source": [
    "Now, we want to create a new variable which indicates the type of animal which acts as the source of the food. To do that, first we'll create a dictionary to map the food to the animals. Then, we'll use map function to map the dictionary's values to the keys. Let's see how is it done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vp_MTQ9wdt3X"
   },
   "outputs": [],
   "source": [
    "meat_to_animal = {\n",
    "'bacon': 'pig',\n",
    "'pulled pork': 'pig',\n",
    "'pastrami': 'cow',\n",
    "'corned beef': 'cow',\n",
    "'honey ham': 'pig',\n",
    "'nova lox': 'salmon'\n",
    "}\n",
    "\n",
    "def meat_2_animal(series):\n",
    "    if series['food'] == 'bacon':\n",
    "        return 'pig'\n",
    "    elif series['food'] == 'pulled pork':\n",
    "        return 'pig'\n",
    "    elif series['food'] == 'pastrami':\n",
    "        return 'cow'\n",
    "    elif series['food'] == 'corned beef':\n",
    "        return 'cow'\n",
    "    elif series['food'] == 'honey ham':\n",
    "        return 'pig'\n",
    "    else:\n",
    "        return 'salmon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_MCdb7QdxIi"
   },
   "outputs": [],
   "source": [
    "#create a new variable\n",
    "data['animal'] = # Use map to change the values.\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RftEZhBVdzSb"
   },
   "outputs": [],
   "source": [
    "#another way of doing it is: convert the food values to the lower case and apply the function\n",
    "lower = lambda x: x.lower()\n",
    "data['food'] = data['food'].apply(lower)\n",
    "data['animal2'] = data.apply(meat_2_animal, axis='columns')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKyqSdiSd4qh"
   },
   "source": [
    "Another way to create a new variable is by using the assign function. With this tutorial, as you keep discovering the new functions, you'll realize how powerful pandas is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kZlcv8Bd1T_"
   },
   "outputs": [],
   "source": [
    "data.assign(new_variable = data['ounces']*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiEZnbdvd6ZK"
   },
   "outputs": [],
   "source": [
    "#Let's remove the column animal2 from our data frame.\n",
    "\n",
    "data.drop('animal2',axis='columns',inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0bhr1BHod_UP"
   },
   "source": [
    "We frequently find missing values in our data set. A quick method for imputing missing values is by filling the missing value with any random number. Not just missing values, you may find lots of outliers in your data set, which might require replacing. Let's see how can we replace values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ggLoydQLd9o7"
   },
   "outputs": [],
   "source": [
    "#Series function from pandas are used to create arrays\n",
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58vjehIkeBOr"
   },
   "outputs": [],
   "source": [
    "#replace -999 with NaN values\n",
    "data.replace(-999, np.nan,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DTdoGmnreCpo"
   },
   "outputs": [],
   "source": [
    "#We can also replace multiple values at once.\n",
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "data.replace([-999,-1000],np.nan,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7f2VcMeTeIyp"
   },
   "source": [
    "**Now, let's learn how to rename column names and axis (row names).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72a_056EeEmX"
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),index=['Ohio', 'Colorado', 'New York'],columns=['one', 'two', 'three', 'four'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVe7pWc2eKXp"
   },
   "outputs": [],
   "source": [
    "#Using rename function\n",
    "data.rename(index = {'Ohio':'SanF'}, columns={'one':'one_p','two':'two_p'},inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxyt9uI5eMGc"
   },
   "outputs": [],
   "source": [
    "#You can also use string functions\n",
    "data.rename(index = str.upper, columns=str.title,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgUZeyKqeNoE"
   },
   "outputs": [],
   "source": [
    "#Next, we'll learn to categorize (bin) continuous variables.\n",
    "\n",
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJiPjmy8ePuB"
   },
   "outputs": [],
   "source": [
    "# We'll divide the ages into bins such as 18-25, 26-35,36-60 and 60 and above.\n",
    "\n",
    "#Understand the output - '(' means the value is included in the bin, '[' means the value is excluded\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "cats = pd.cut(ages, bins)\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i51nbryMeVEJ"
   },
   "outputs": [],
   "source": [
    "#To include the right bin value, we can do:\n",
    "pd.cut(ages,bins,right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHKFw1_tebVC"
   },
   "outputs": [],
   "source": [
    "#pandas library intrinsically assigns an encoding to categorical variables.\n",
    "cats.codes\n",
    "\n",
    "#cats.labels can also be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9Zymtx-ecrr"
   },
   "outputs": [],
   "source": [
    "#Let's check how many observations fall under each bin\n",
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3SoHCb0eqms"
   },
   "outputs": [],
   "source": [
    "#Also, we can pass a unique name to each label.\n",
    "\n",
    "bin_names = ['Youth', 'YoungAdult', 'MiddleAge', 'Senior']\n",
    "new_cats = pd.cut(ages, bins,labels=bin_names)\n",
    "\n",
    "pd.value_counts(new_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgU0UitRetsx"
   },
   "outputs": [],
   "source": [
    "#we can also calculate their cumulative sum\n",
    "pd.value_counts(new_cats).cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGwby0dGeyAV"
   },
   "source": [
    "Let's proceed and learn about grouping data and creating pivots in pandas. It's an immensely important data analysis method which you'd probably have to use on every data set you work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjUlH2pQev37"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
    "                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
    "                   'data1' : np.random.randn(5),\n",
    "                   'data2' : np.random.randn(5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSQBDSbyez18"
   },
   "outputs": [],
   "source": [
    "#calculate the mean of data1 column by key1\n",
    "grouped = df['data1'].groupby(df['key1'])\n",
    "grouped.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37PHx-cwe2XI"
   },
   "outputs": [],
   "source": [
    "# Now, let's see how to slice the data frame.\n",
    "dates = pd.date_range('20130101',periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UaZO8LEe9J8"
   },
   "outputs": [],
   "source": [
    "#get first n rows from the data frame\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_ld_0Wde_Vg"
   },
   "outputs": [],
   "source": [
    "#slice based on date range\n",
    "df['20130101':'20130104']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRgGzhWOfAyP"
   },
   "outputs": [],
   "source": [
    "#slicing based on column names\n",
    "df.loc[:,['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fL2kXshGfCFf"
   },
   "outputs": [],
   "source": [
    "#slicing based on both row index labels and column names\n",
    "df.loc['20130102':'20130103',['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAhj98h4fDel"
   },
   "outputs": [],
   "source": [
    "#slicing based on index of columns\n",
    "df.iloc[3] \n",
    "\n",
    "#returns 4th row (index is 3rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLALOx2vfJCW"
   },
   "outputs": [],
   "source": [
    "#returns a specific range of rows\n",
    "df.iloc[2:4, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WS6-Zw3yfKuB"
   },
   "outputs": [],
   "source": [
    "#returns specific rows and columns using lists containing columns or row indexes\n",
    "df.iloc[[1,5],[0,2]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORZPjpRyfMNt"
   },
   "outputs": [],
   "source": [
    "#Similarly, we can do Boolean indexing based on column values as well. This helps in filtering a data set based on a pre-defined condition.\n",
    "\n",
    "df[df.A > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3-dgQqEfOdL"
   },
   "outputs": [],
   "source": [
    "#we can copy the data set\n",
    "df2 = df.copy()\n",
    "df2['E']=['one', 'one','two','three','four','three']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PAbxaHpfRaX"
   },
   "outputs": [],
   "source": [
    "#select rows based on column values\n",
    "df2[df2['E'].isin(['two','four'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udRXo4WKfTC0"
   },
   "outputs": [],
   "source": [
    "#select all rows except those with two and four\n",
    "df2[~df2['E'].isin(['two','four'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tqs7hxYqfUj0"
   },
   "outputs": [],
   "source": [
    "#We can also use a query method to select columns based on a criterion. Let's see how!\n",
    "\n",
    "#list all columns where A is greater than C\n",
    "df.query('A > C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdN5WhAVfWrh"
   },
   "outputs": [],
   "source": [
    "#using OR condition\n",
    "df.query('A < B | C > A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXz96Bxmfcfz"
   },
   "source": [
    "Pivot tables are extremely useful in analyzing data using a customized tabular format. I think, among other things, Excel is popular because of the pivot table option. It offers a super-quick way to analyze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKok_wfmfaeW"
   },
   "outputs": [],
   "source": [
    "#create a data frame\n",
    "data = pd.DataFrame({'group': ['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],\n",
    "                 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x3tW10DYfeDH"
   },
   "outputs": [],
   "source": [
    "#calculate means of each group\n",
    "data.pivot_table(values='ounces',index='group',aggfunc=np.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1y58JVBtf1rX"
   },
   "outputs": [],
   "source": [
    "#calculate count by each group\n",
    "data.pivot_table(values='ounces',index='group',aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsrOnr-hf7uf"
   },
   "source": [
    "**Up till now, we've become familiar with the basics of pandas library using toy examples. Now, we'll take up a real-life data set and use our newly gained knowledge to explore it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VcMVxO5lgIKq"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLQzWfYFgIgg"
   },
   "source": [
    "#<a name=\"exploring\"></a>Exploring an ML Dataset\n",
    "\n",
    "\n",
    "We'll work with the popular adult data set.The data set has been taken from **UCI Machine Learning Repository**. You can download the [data from here](https://s3-ap-southeast-1.amazonaws.com/he-public-data/datafiles19cdaf8.zip). In this data set, the dependent variable is \"target.\" It is a binary classification problem. We need to predict if the salary of a given person is less than or more than 50K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XG0pX8wLhW1_"
   },
   "outputs": [],
   "source": [
    "'''Here, you've to upload the .csv data file from your system after downloading it from the above link.\n",
    "Open the file and export the files to a position where it can be easily fetched'''\n",
    "\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WK1Z5HF0i4h4"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPcDDL5zi8_w"
   },
   "outputs": [],
   "source": [
    "#importing pandas using read_csv\n",
    "import pandas as pd\n",
    "filename = 'train.csv'\n",
    "train = pd.read_csv(filename)\n",
    "filename_test = 'test.csv'\n",
    "test = pd.read_csv(filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VQ-63JWg_Jy"
   },
   "outputs": [],
   "source": [
    "#train\n",
    "#un comment the above code to print the data in train.csv\n",
    "\n",
    "#test\n",
    "#un comment the above code to print the data in test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxiVH8wnhBoM"
   },
   "outputs": [],
   "source": [
    "#check data set\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUIgQiDAj4Ty"
   },
   "source": [
    "We see that, the train data has 32561 rows and 15 columns. Out of these 15 columns, 6 have integers classes and the rest have object (or character) classes. Similarly, we can check for test data. An alternative way of quickly checking rows and columns is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXxPxmjtjW1I"
   },
   "outputs": [],
   "source": [
    "print (\"The train data has\",train.shape)\n",
    "print (\"The test data has\",test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mu6w_36Zj8TI"
   },
   "outputs": [],
   "source": [
    "#Let have a glimpse of the data set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVjPGtYuj9-l"
   },
   "outputs": [],
   "source": [
    "nans = train.shape[0] - train.dropna().shape[0]\n",
    "print (\"%d rows have missing values in the train data\" %nans)\n",
    "\n",
    "nand = test.shape[0] - test.dropna().shape[0]\n",
    "print (\"%d rows have missing values in the test data\" %nand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4Jw6ZMXkHnC"
   },
   "source": [
    "**#We should be more curious to know which columns have missing values.\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ArmwMxukA-M"
   },
   "outputs": [],
   "source": [
    "\n",
    "#only 3 columns have missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kb-sPQeokIyv"
   },
   "outputs": [],
   "source": [
    "#Let's count the number of unique values from character variables.\n",
    "\n",
    "cat = train.select_dtypes(include=['O'])\n",
    "cat.apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uC6CpqQEkNK3"
   },
   "source": [
    "Since missing values are found in all 3 character variables, let's impute these missing values with their respective modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwaNdDnekLln"
   },
   "outputs": [],
   "source": [
    "#Education\n",
    "train.workclass.value_counts(sort=True)\n",
    "train.workclass.fillna('Private',inplace=True)\n",
    "\n",
    "\n",
    "#Occupation\n",
    "train.occupation.value_counts(sort=True)\n",
    "train.occupation.fillna('Prof-specialty',inplace=True)\n",
    "\n",
    "\n",
    "#Native Country\n",
    "train['native.country'].value_counts(sort=True)\n",
    "train['native.country'].fillna('United-States',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvUhlJDbkQ5_"
   },
   "outputs": [],
   "source": [
    "# Let's check again if there are any missing values left.\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FVbUioakXSg"
   },
   "source": [
    "Now, we'll check the target variable to investigate if this data is imbalanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51D1eG4qkTsa"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#check proportion of target variable\n",
    "train.target.value_counts()/train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUXs01bUkaHl"
   },
   "source": [
    "We see that 75% of the data set belongs to <=50K class. This means that even if we take a rough guess of target prediction as <=50K, we'll get 75% accuracy. Isn't that amazing? Let's create a cross tab of the target variable with education. With this, we'll try to understand the influence of education on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HR6nNlykXyV"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(train.education, train.target,margins=True)/train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcJbOTkUkedm"
   },
   "source": [
    "We see that out of 75% people with <=50K salary, 27% people are high school graduates, which is correct as people with lower levels of education are expected to earn less. On the other hand, out of 25% people with >=50K salary, 6% are bachelors and 5% are high-school grads. Now, this pattern seems to be a matter of concern. That's why we'll have to consider more variables before coming to a conclusion.\n",
    "\n",
    "If you've come this far, you might be curious to get a taste of building your first machine learning model. In the coming week we'll share an exclusive tutorial on machine learning in python. However, let's get a taste of it here.\n",
    "\n",
    "We'll use the famous and formidable scikit learn library. Scikit learn accepts data in numeric format. Now, we'll have to convert the character variable into numeric. We'll use the labelencoder function.\n",
    "\n",
    "In label encoding, each unique value of a variable gets assigned a number, i.e., let's say a variable color has four values ['red','green','blue','pink'].\n",
    "\n",
    "Label encoding this variable will return output as: red = 2 green = 0 blue = 1 pink = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cR0pJC2bkcIN"
   },
   "outputs": [],
   "source": [
    "#load sklearn and encode all object type variables\n",
    "from sklearn import preprocessing\n",
    "\n",
    "for x in train.columns:\n",
    "    if train[x].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[x].values))\n",
    "        train[x] = lbl.transform(list(train[x].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUhYCVjFkgV_"
   },
   "outputs": [],
   "source": [
    "#Let's check the changes applied to the data set.\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Txo8tyvkjdZ"
   },
   "outputs": [],
   "source": [
    "#As we can see, all the variables have been converted to numeric, including the target variable.\n",
    "\n",
    "#<50K = 0 and >50K = 1\n",
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h1sKkJbksDR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mG6NGlIoksNs"
   },
   "source": [
    "#<a name=\"building\"></a>Building a Random Forest Model\n",
    "\n",
    "<a name=\"buildingthemodel\"></a>Let's create a random forest model and check the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sg_xiQPXkmKF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = train['target']\n",
    "del train['target']\n",
    "\n",
    "X = train\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1,stratify=y)\n",
    "\n",
    "#train the RF classifier\n",
    "clf = RandomForestClassifier(n_estimators = 500, max_depth = 6)\n",
    "clf.fit(X_train,y_train) no\n",
    "\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
    "                min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
    "                verbose=0, warm_start=False)\n",
    "\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SZ6fnfxlR9d"
   },
   "source": [
    "**<a name=\"prediction\"></a>Now, let's make prediction on the test set and check the model's accuracy.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUm0nCnhk1G5"
   },
   "outputs": [],
   "source": [
    "#make prediction and check model's accuracy\n",
    "prediction = clf.predict(X_test)\n",
    "acc =  accuracy_score(np.array(y_test),prediction)\n",
    "print ('The accuracy of Random Forest is {}'.format(acc))\n",
    "\n",
    "#if you get a numpy module missing error, then import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QxqTV-JlcKC"
   },
   "source": [
    "Well, we can do tons of things on this data and improve the accuracy. We'll learn about it in future articles. What's next?\n",
    "\n",
    "In this tutorial, we divided the train data into two halves and made prediction on the test data. As your exercise, you should use this model and make prediction on the test data we loaded initially. You can perform same set of steps we did on the train data to perform the basic necessities on the available data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i39JuKQTZLnD"
   },
   "source": [
    "[Go to Top](#gotop)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Numpy and Pandas.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
